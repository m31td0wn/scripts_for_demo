{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType, TimestampType, IntegerType\n",
    "\n",
    "\n",
    "spark_jars_packages = \",\".join(\n",
    "        [\n",
    "        \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0\",\n",
    "        \"org.postgresql:postgresql:42.4.0\"\n",
    "        ]\n",
    ")\n",
    "\n",
    "def f_range_cnt(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000\n",
    "\n",
    "    lat1 = f.radians(lat1)\n",
    "    lon1 = f.radians(lon1)\n",
    "    lat2 = f.radians(lat2)\n",
    "    lon2 = f.radians(lon2)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = (f.sin(dlat/2))**2 + f.cos(lat1) * f.cos(lat2) * (f.sin(dlon/2))**2\n",
    "    c = 2 * f.atan2(f.sqrt(a), f.sqrt(1-a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "def spark_init(test_name) -> SparkSession:\n",
    "    spark = SparkSession.builder \\\n",
    "    .master('local') \\\n",
    "    .appName(test_name) \\\n",
    "    .config(\"spark.jars.packages\", spark_jars_packages) \\\n",
    "    .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "postgresql_settings = {\n",
    "    'user': 'student',\n",
    "    'password': 'de-student',\n",
    "    'url': 'jdbc:postgresql://rc1a-fswjkpli01zafgjm.mdb.yandexcloud.net:6432/de',\n",
    "    'driver': 'org.postgresql.Driver',\n",
    "    'dbtable': 'public.marketing_companies'   \n",
    "}\n",
    "\n",
    "def read_marketing(spark: SparkSession) -> DataFrame:\n",
    "    marketing_df = (spark.read\n",
    "                    .format('jdbc')\n",
    "                    .options(**postgresql_settings)\n",
    "                    .load())\n",
    "    return marketing_df\n",
    "\n",
    "\n",
    "\n",
    "kafka_security_options = {\n",
    "    'kafka.bootstrap.servers': 'rc1b-2erh7b35n4j4v869.mdb.yandexcloud.net:9091', \n",
    "    'kafka.security.protocol': 'SASL_SSL',\n",
    "    'kafka.sasl.mechanism': 'SCRAM-SHA-512',\n",
    "    'kafka.sasl.jaas.config': 'org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"de-student\\\" password=\\\"ltcneltyn\\\";',\n",
    "    \"subscribe\": \"student.topic.cohort28.dimaneboris\", \n",
    "}\n",
    "\n",
    "incomming_message_schema = StructType(\n",
    "                    [\n",
    "                        StructField(\"client_id\", StringType()),\n",
    "                        StructField(\"timestamp\", DoubleType()),\n",
    "                        StructField(\"lat\", DoubleType()),\n",
    "                        StructField(\"lon\", DoubleType())\n",
    "                    ]\n",
    "    )\n",
    "\n",
    "\n",
    "def read_client_stream(spark: SparkSession) -> DataFrame:\n",
    "    df = (spark.readStream\n",
    "    .format('kafka')\n",
    "    .options(**kafka_security_options)\n",
    "    .load())\n",
    "    transform_df = df.select(f.from_json(f.col(\"value\").cast('string'), incomming_message_schema).alias(\"value_parsed\")) \\\n",
    "                     .selectExpr('value_parsed.*') \\\n",
    "                     .withColumn('timestamp',f.from_unixtime(f.col('timestamp'), \"yyyy-MM-dd' 'HH:mm:ss.SSS\").cast(TimestampType())) \\\n",
    "                     .dropDuplicates() \\\n",
    "                     .withWatermark('timestamp', '10 minute')\n",
    "    return transform_df\n",
    "\n",
    "\n",
    "def join(user_df, marketing_df) -> DataFrame:\n",
    "    result_df = user_df.crossJoin(marketing_df) \\\n",
    "                       .withColumn('distance', f_range_cnt(f.col('lat'), f.col('lon'), f.col('point_lat'), f.col('point_lon'))) \\\n",
    "                       .withColumn('created_at', f.current_timestamp()) \\\n",
    "                       .where('distance <= 1000') \\\n",
    "                       .selectExpr(['client_id', \n",
    "                                    'id as adv_campaign_id',\n",
                                         ''distance',\n",
    "                                    'name as adv_campaign_name',\n",
    "                                    'description as adv_campaign_description',\n",
    "                                    'start_time as adv_campaign_start_time',\n",
    "                                    'end_time as adv_campaign_end_time',\n",
    "                                    'point_lat as adv_campaign_point_lat',\n",
    "                                    'point_lon as adv_campaign_point_lon',\n",
    "                                    'created_at'])\n",
    "    return result_df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = spark_init('join stream')\n",
    "    client_stream = read_client_stream(spark)\n",
    "    marketing_df = read_marketing(spark)\n",
    "    result = join(client_stream, marketing_df)\n",
    "\n",
    "    query = (result\n",
    "             .writeStream\n",
    "             .outputMode(\"append\")\n",
    "             .format(\"console\")\n",
    "             .option(\"truncate\", False)\n",
    "             .start())\n",
    "    query.awaitTermination()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
